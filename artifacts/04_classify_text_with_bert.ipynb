{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ6SNYq_tVVC"
   },
   "source": [
    "# Classify text with BERT\n",
    "\n",
    "### Learning Objectives\n",
    "1. Learn how to load a pre-trained BERT model from TensorFlow Hub\n",
    "2. Learn how to build your own model by combining with a classifier\n",
    "3. Learn how to train a BERT model by fine-tuning\n",
    "4. Learn how to save your trained model and use it\n",
    "5. Learn how to evaluate a text classification model\n",
    "\n",
    "This lab will show you how to fine-tune BERT to perform sentiment analysis on a dataset of plain-text IMDB movie reviews.\n",
    "In addition to training a model, you will learn how to preprocess text into an appropriate format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PHBpLPuQdmK"
   },
   "source": [
    "## About BERT\n",
    "\n",
    "[BERT](https://arxiv.org/abs/1810.04805) and other Transformer encoder architectures have been wildly successful on a variety of tasks in NLP (natural language processing). They compute vector-space representations of natural language that are suitable for use in deep learning models. The BERT family of models uses the Transformer encoder architecture to process each token of input text in the full context of all tokens before and after, hence the name: Bidirectional Encoder Representations from Transformers. \n",
    "\n",
    "BERT models are usually pre-trained on a large corpus of text, then fine-tuned for specific tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a New Conda Environment\n",
    "\n",
    "1. If you haven't already created a CUDA enabled environment then go to https://www.youtube.com/watch?v=jZsopVyJktc and make sure you have one set up\n",
    "2. Create a clone of the CUDA environment for our use by going to the Anaconda prompt and typing\n",
    "```bash\n",
    "conda create --name your_env_name --clone tf_gpu\n",
    "```\n",
    "2. Make sure use the new environment for this notebook.\n",
    "3. Enjoy the code! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the packages we need\n",
    "\n",
    "NOTE: when you try to run any cell you will be prompted to install ipykernel. Make sure to install it as prompted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-models-official\n",
      "  Using cached tf_models_official-2.17.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting Cython (from tf-models-official)\n",
      "  Using cached Cython-3.0.11-cp39-cp39-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting Pillow (from tf-models-official)\n",
      "  Using cached pillow-10.4.0-cp39-cp39-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting gin-config (from tf-models-official)\n",
      "  Using cached gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting google-api-python-client>=1.6.7 (from tf-models-official)\n",
      "  Using cached google_api_python_client-2.143.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting immutabledict (from tf-models-official)\n",
      "  Using cached immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting kaggle>=1.3.9 (from tf-models-official)\n",
      "  Using cached kaggle-1.6.17-py3-none-any.whl\n",
      "Collecting matplotlib (from tf-models-official)\n",
      "  Using cached matplotlib-3.9.2-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tf-models-official) (1.26.4)\n",
      "Collecting oauth2client (from tf-models-official)\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting opencv-python-headless (from tf-models-official)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting pandas>=0.22.0 (from tf-models-official)\n",
      "  Using cached pandas-2.2.2-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: psutil>=5.4.3 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tf-models-official) (6.0.0)\n",
      "Collecting py-cpuinfo>=3.3.0 (from tf-models-official)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pycocotools (from tf-models-official)\n",
      "  Using cached pycocotools-2.0.8-cp39-cp39-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting pyyaml>=6.0.0 (from tf-models-official)\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting sacrebleu (from tf-models-official)\n",
      "  Using cached sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting scipy>=0.19.1 (from tf-models-official)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Collecting sentencepiece (from tf-models-official)\n",
      "  Using cached sentencepiece-0.2.0-cp39-cp39-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting seqeval (from tf-models-official)\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: six in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tf-models-official) (1.16.0)\n",
      "Collecting tensorflow-datasets (from tf-models-official)\n",
      "  Using cached tensorflow_datasets-4.9.3-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in c:\\users\\zain_\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official) (0.16.1)\n",
      "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official)\n",
      "  Using cached tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
      "INFO: pip is looking at multiple versions of tf-models-official to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-models-official\n",
      "  Using cached tf_models_official-2.16.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Using cached tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Using cached tf_models_official-2.14.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Using cached tf_models_official-2.14.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Using cached tf_models_official-2.14.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Using cached tf_models_official-2.13.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Using cached tf_models_official-2.13.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyyaml<5.4.0,>=5.1 (from tf-models-official)\n",
      "  Using cached PyYAML-5.3.1-cp39-cp39-win_amd64.whl.metadata (1.7 kB)\n",
      "INFO: pip is still looking at multiple versions of tf-models-official to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-models-official\n",
      "  Using cached tf_models_official-2.13.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyyaml<6.0,>=5.1 (from tf-models-official)\n",
      "  Using cached PyYAML-5.4.1-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tf-models-official\n",
      "  Using cached tf_models_official-2.12.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tensorflow-addons (from tf-models-official)\n",
      "  Using cached tensorflow_addons-0.22.0-cp39-cp39-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting tf-models-official\n",
      "  Using cached tf_models_official-2.12.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Using cached tf_models_official-2.11.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Using cached tf_models_official-2.11.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached tf_models_official-2.11.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Using cached tf_models_official-2.11.3-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Using cached tf_models_official-2.11.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Using cached tf_models_official-2.11.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opencv-python-headless==4.5.2.52 (from tf-models-official)\n",
      "  Using cached opencv_python_headless-4.5.2.52-cp39-cp39-win_amd64.whl.metadata (17 kB)\n",
      "Collecting tf-models-official\n",
      "  Using cached tf_models_official-2.10.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting sacrebleu==2.2.0 (from tf-models-official)\n",
      "  Using cached sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\n",
      "Collecting tensorflow-text~=2.10.0 (from tf-models-official)\n",
      "  Using cached tensorflow_text-2.10.0-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: tensorflow~=2.10.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tf-models-official) (2.10.1)\n",
      "Collecting tf-slim>=1.1.0 (from tf-models-official)\n",
      "  Using cached tf_slim-1.1.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting portalocker (from sacrebleu==2.2.0->tf-models-official)\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting regex (from sacrebleu==2.2.0->tf-models-official)\n",
      "  Using cached regex-2024.7.24-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu==2.2.0->tf-models-official)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from sacrebleu==2.2.0->tf-models-official) (0.4.6)\n",
      "Collecting lxml (from sacrebleu==2.2.0->tf-models-official)\n",
      "  Using cached lxml-5.3.0-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.34.0)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Using cached google_api_core-2.19.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official) (2.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official) (2.32.3)\n",
      "Collecting tqdm (from kaggle>=1.3.9->tf-models-official)\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting python-slugify (from kaggle>=1.3.9->tf-models-official)\n",
      "  Using cached python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official) (2.2.2)\n",
      "Collecting bleach (from kaggle>=1.3.9->tf-models-official)\n",
      "  Using cached bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=0.22.0->tf-models-official)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=0.22.0->tf-models-official)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (3.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (24.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (72.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (2.10.0)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\zain_\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-hub>=0.6.0->tf-models-official) (2.15.0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow~=2.10.0->tf-models-official)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting dm-tree~=0.1.1 (from tensorflow-model-optimization>=0.4.1->tf-models-official)\n",
      "  Using cached dm_tree-0.1.8-cp39-cp39-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->tf-models-official)\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->tf-models-official)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->tf-models-official)\n",
      "  Using cached fonttools-4.53.1-cp39-cp39-win_amd64.whl.metadata (165 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->tf-models-official)\n",
      "  Using cached kiwisolver-1.4.5-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->tf-models-official)\n",
      "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib->tf-models-official)\n",
      "  Using cached importlib_resources-6.4.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from oauth2client->tf-models-official) (0.6.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from oauth2client->tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from oauth2client->tf-models-official) (4.9)\n",
      "Collecting scikit-learn>=0.21.3 (from seqeval->tf-models-official)\n",
      "  Using cached scikit_learn-1.5.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->tf-models-official)\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting array-record (from tensorflow-datasets->tf-models-official)\n",
      "  Using cached array_record-0.4.1-py39-none-any.whl.metadata (503 bytes)\n",
      "Collecting click (from tensorflow-datasets->tf-models-official)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting etils>=0.9.0 (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official)\n",
      "  Using cached etils-1.5.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting promise (from tensorflow-datasets->tf-models-official)\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "INFO: pip is looking at multiple versions of tensorflow-datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow-datasets (from tf-models-official)\n",
      "  Using cached tensorflow_datasets-4.9.2-py3-none-any.whl.metadata (9.0 kB)\n",
      "  Using cached tensorflow_datasets-4.9.1-py3-none-any.whl.metadata (9.0 kB)\n",
      "  Using cached tensorflow_datasets-4.9.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets->tf-models-official)\n",
      "  Using cached tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting toml (from tensorflow-datasets->tf-models-official)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-models-official) (0.43.0)\n",
      "Collecting fsspec (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: zipp in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official) (3.20.1)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Using cached proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official) (5.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.8)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.21.3->seqeval->tf-models-official)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.21.3->seqeval->tf-models-official)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (3.0.4)\n",
      "Collecting webencodings (from bleach->kaggle>=1.3.9->tf-models-official)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from portalocker->sacrebleu==2.2.0->tf-models-official) (306)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle>=1.3.9->tf-models-official)\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow-metadata to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets->tf-models-official)\n",
      "  Using cached tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Using cached tensorflow_metadata-1.13.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Using cached tensorflow_metadata-1.13.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (2.0.0)\n",
      "INFO: pip is looking at multiple versions of googleapis-common-protos to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Using cached googleapis_common_protos-1.64.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Using cached googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Using cached googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (8.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (2.1.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\zain_\\anaconda3\\envs\\glabs2\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (3.2.2)\n",
      "Using cached tf_models_official-2.10.1-py2.py3-none-any.whl (2.2 MB)\n",
      "Using cached sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
      "Using cached google_api_python_client-2.143.0-py2.py3-none-any.whl (12.2 MB)\n",
      "Using cached pandas-2.2.2-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached PyYAML-5.4.1-cp39-cp39-win_amd64.whl (213 kB)\n",
      "Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "Using cached tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
      "Using cached tensorflow_text-2.10.0-cp39-cp39-win_amd64.whl (5.0 MB)\n",
      "Using cached tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Using cached Cython-3.0.11-cp39-cp39-win_amd64.whl (2.8 MB)\n",
      "Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Using cached immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached matplotlib-3.9.2-cp39-cp39-win_amd64.whl (7.8 MB)\n",
      "Using cached pillow-10.4.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached pycocotools-2.0.8-cp39-cp39-win_amd64.whl (85 kB)\n",
      "Using cached sentencepiece-0.2.0-cp39-cp39-win_amd64.whl (991 kB)\n",
      "Using cached tensorflow_addons-0.22.0-cp39-cp39-win_amd64.whl (729 kB)\n",
      "Using cached tensorflow_datasets-4.9.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Using cached contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached dm_tree-0.1.8-cp39-cp39-win_amd64.whl (101 kB)\n",
      "Using cached etils-1.5.2-py3-none-any.whl (140 kB)\n",
      "Using cached fonttools-4.53.1-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Using cached google_api_core-2.19.2-py3-none-any.whl (139 kB)\n",
      "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached importlib_resources-6.4.4-py3-none-any.whl (35 kB)\n",
      "Using cached kiwisolver-1.4.5-cp39-cp39-win_amd64.whl (56 kB)\n",
      "Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached scikit_learn-1.5.1-cp39-cp39-win_amd64.whl (11.0 MB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Using cached array_record-0.4.1-py39-none-any.whl (3.0 MB)\n",
      "Using cached bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached lxml-5.3.0-cp39-cp39-win_amd64.whl (3.8 MB)\n",
      "Using cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Using cached regex-2024.7.24-cp39-cp39-win_amd64.whl (269 kB)\n",
      "Using cached tensorflow_metadata-1.13.0-py3-none-any.whl (53 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, text-unidecode, sentencepiece, pytz, py-cpuinfo, gin-config, dm-tree, uritemplate, tzdata, typeguard, tqdm, toml, threadpoolctl, tabulate, scipy, regex, pyyaml, python-slugify, pyparsing, proto-plus, promise, portalocker, Pillow, opencv-python-headless, lxml, kiwisolver, joblib, importlib-resources, immutabledict, googleapis-common-protos, fsspec, fonttools, etils, Cython, cycler, contourpy, click, bleach, absl-py, tf-slim, tensorflow-model-optimization, tensorflow-metadata, tensorflow-addons, scikit-learn, sacrebleu, pandas, matplotlib, kaggle, httplib2, seqeval, pycocotools, oauth2client, google-auth-httplib2, google-api-core, google-api-python-client, array-record, tensorflow-datasets, tensorflow-text, tf-models-official\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 2.1.0\n",
      "    Uninstalling absl-py-2.1.0:\n",
      "      Successfully uninstalled absl-py-2.1.0\n",
      "Successfully installed Cython-3.0.11 Pillow-10.4.0 absl-py-1.4.0 array-record-0.4.1 bleach-6.1.0 click-8.1.7 contourpy-1.3.0 cycler-0.12.1 dm-tree-0.1.8 etils-1.5.2 fonttools-4.53.1 fsspec-2024.6.1 gin-config-0.5.0 google-api-core-2.19.2 google-api-python-client-2.143.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.63.1 httplib2-0.22.0 immutabledict-4.2.0 importlib-resources-6.4.4 joblib-1.4.2 kaggle-1.6.17 kiwisolver-1.4.5 lxml-5.3.0 matplotlib-3.9.2 oauth2client-4.1.3 opencv-python-headless-4.10.0.84 pandas-2.2.2 portalocker-2.10.1 promise-2.3 proto-plus-1.24.0 py-cpuinfo-9.0.0 pycocotools-2.0.8 pyparsing-3.1.4 python-slugify-8.0.4 pytz-2024.1 pyyaml-5.4.1 regex-2024.7.24 sacrebleu-2.2.0 scikit-learn-1.5.1 scipy-1.13.1 sentencepiece-0.2.0 seqeval-1.2.2 tabulate-0.9.0 tensorflow-addons-0.22.0 tensorflow-datasets-4.9.0 tensorflow-metadata-1.13.0 tensorflow-model-optimization-0.8.0 tensorflow-text-2.10.0 text-unidecode-1.3 tf-models-official-2.10.1 tf-slim-1.1.0 threadpoolctl-3.5.0 toml-0.10.2 tqdm-4.66.5 typeguard-2.13.3 tzdata-2024.1 uritemplate-4.1.1 webencodings-0.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement maplotlib (from versions: none)\n",
      "ERROR: No matching distribution found for maplotlib\n"
     ]
    }
   ],
   "source": [
    "! pip install tf-models-official\n",
    "! pip install maplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os  # Provides a way of using operating system dependent functionality\n",
    "import warnings  # Used to handle warnings in the code\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime  # Import datetime module to work with dates and times\n",
    "import shutil  # High-level file operations such as copying and removal of files\n",
    "\n",
    "import matplotlib.pyplot as plt  # Matplotlib plotting library for creating static, animated, and interactive visualizations\n",
    "\n",
    "import tensorflow as tf  # Core TensorFlow library for machine learning and neural networks\n",
    "import tensorflow_hub as hub  # TensorFlow Hub is a library for reusable machine learning modules\n",
    "import tensorflow_text as text  # TensorFlow Text provides text-based operations for TensorFlow\n",
    "import tensorflow_addons as tfa  # A collection of additional functionality not available in TensorFlow core\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_XgTpm9ZxoN9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set TensorFlow logger level to only display errors\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# Set TensorFlow C++ logging level to reduce output\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# Update PATH to include the directory containing saved_model_cli if necessary\n",
    "# Adjust the anaconda_path based on your local Anaconda environment setup\n",
    "anaconda_path = os.path.expanduser(\"~/anaconda3/envs/glabs/bin\")\n",
    "os.environ[\"PATH\"] = f\"{anaconda_path}:{os.environ['PATH']}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Support\n",
    "\n",
    "to check if you have a GPU attached. Run the following.\n",
    "\n",
    "NOTE: You will absolutely need to have at least one GPU recognized by TensorFlow or the training can take hours instead of minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "# Print the number of available GPUs for TensorFlow\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices(\"GPU\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6MugfEgDRpY"
   },
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "This notebook trains a sentiment analysis model to classify movie reviews as *positive* or *negative*, based on the text of the review.\n",
    "\n",
    "You'll use the [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/) that contains the text of 50,000 movie reviews from the [Internet Movie Database](https://www.imdb.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vnvd4mrtPHHV"
   },
   "source": [
    "### Download the IMDB dataset\n",
    "\n",
    "Let's download and extract the dataset, then explore the directory structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pOdqCMoQDRJL",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at: C:\\Users\\Zain_\\Downloads\\tfds_datasets\\aclImdb\n",
      "Training data directory: C:\\Users\\Zain_\\Downloads\\tfds_datasets\\aclImdb\\train\n"
     ]
    }
   ],
   "source": [
    "# URL for the IMDB dataset (for sentiment analysis)\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "# Set path to the Downloads folder on Windows\n",
    "# NOTE: You need to create the 'tfds_datasets' folder in your Downloads folder\n",
    "path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", \"tfds_datasets\")\n",
    "\n",
    "# Ensure the directory exists, create it if it doesn't\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Define the expected dataset directory and file paths\n",
    "dataset_dir = os.path.join(path, \"aclImdb\")\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "dataset_file = os.path.join(path, \"aclImdb_v1.tar.gz\")\n",
    "\n",
    "# Check if the training data directory already exists\n",
    "if not os.path.exists(train_dir):\n",
    "    if not os.path.exists(dataset_file):\n",
    "        # Download and extract the dataset if not already downloaded\n",
    "        dataset = tf.keras.utils.get_file(\n",
    "            \"aclImdb_v1.tar.gz\", url, \n",
    "            untar=True, \n",
    "            cache_dir=path, \n",
    "            cache_subdir=\"\"\n",
    "        )\n",
    "    else:\n",
    "        # Extract the dataset if it has been downloaded but not extracted\n",
    "        dataset = tf.keras.utils.get_file(\n",
    "            \"aclImdb_v1.tar.gz\", url, \n",
    "            untar=True, \n",
    "            cache_dir=path, \n",
    "            cache_subdir=\"\"\n",
    "        )\n",
    "\n",
    "    # Remove unused folders (e.g., 'unsup') to simplify the dataset structure\n",
    "    remove_dir = os.path.join(train_dir, \"unsup\")\n",
    "    if os.path.exists(remove_dir):\n",
    "        shutil.rmtree(remove_dir)\n",
    "\n",
    "    print(f\"Dataset downloaded and extracted to: {dataset_dir}\")\n",
    "else:\n",
    "    print(f\"Dataset already exists at: {dataset_dir}\")\n",
    "\n",
    "# Print the path to the training data directory\n",
    "print(f\"Training data directory: {train_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lN9lWCYfPo7b"
   },
   "source": [
    "Next, you will use the `text_dataset_from_directory` utility to create a labeled `tf.data.Dataset`.\n",
    "\n",
    "The IMDB dataset has already been divided into train and test, but it lacks a validation set. Let's create a validation set using an 80:20 split of the training data by using the `validation_split` argument below.\n",
    "\n",
    "Note:  When using the `validation_split` and `subset` arguments, make sure to either specify a random seed, or to pass `shuffle=False`, so that the validation and training splits have no overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6IwI_2bcIeX8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Datasets created successfully.\n",
      "Class names: ['neg', 'pos']\n",
      "Number of training batches: 625\n",
      "Number of validation batches: 157\n",
      "Number of test batches: 782\n"
     ]
    }
   ],
   "source": [
    "# Set TensorFlow data pipeline options\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32  # Number of samples per gradient update\n",
    "seed = 42  # Random seed for reproducibility\n",
    "\n",
    "# Use the path from the previous cell for the dataset location\n",
    "path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", \"tfds_datasets\")\n",
    "\n",
    "# Function to create a dataset from a directory\n",
    "def create_dataset(directory, validation_split=None, subset=None):\n",
    "    return tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        directory,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        subset=subset,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "# Create the training dataset, using 80% of the data for training\n",
    "raw_train_ds = create_dataset(\n",
    "    os.path.join(path, \"aclImdb\", \"train\"),\n",
    "    validation_split=0.2,  # Use 20% of the data for validation\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Get the class names (e.g., positive, negative) from the dataset\n",
    "class_names = raw_train_ds.class_names\n",
    "\n",
    "# Cache the training dataset and prefetch it for performance optimization\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Create the validation dataset, using the remaining 20% of the data\n",
    "val_ds = create_dataset(\n",
    "    os.path.join(path, \"aclImdb\", \"train\"),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Cache the validation dataset and prefetch it for performance optimization\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Create the test dataset from the test directory\n",
    "test_ds = create_dataset(os.path.join(path, \"aclImdb\", \"test\"))\n",
    "\n",
    "# Cache the test dataset and prefetch it for performance optimization\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Print information about the datasets\n",
    "print(\"Datasets created successfully.\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Number of training batches: {tf.data.experimental.cardinality(train_ds)}\")\n",
    "print(f\"Number of validation batches: {tf.data.experimental.cardinality(val_ds)}\")\n",
    "print(f\"Number of test batches: {tf.data.experimental.cardinality(test_ds)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGm10A5HRGXp"
   },
   "source": [
    "Let's take a look at a few reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JuxDkcvVIoev",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
      "Label : 0 (neg)\n",
      "--------------------------------------------------------------------------------\n",
      "Review: b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n",
      "Label : 0 (neg)\n",
      "--------------------------------------------------------------------------------\n",
      "Review: b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'\n",
      "Label : 1 (pos)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Iterate through a batch of training data\n",
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    # Display the first 3 reviews and their corresponding labels\n",
    "    for i in range(3):\n",
    "        # Print the review text\n",
    "        print(f\"Review: {text_batch.numpy()[i]}\")\n",
    "        \n",
    "        # Get the label (0 or 1) and print the corresponding class name\n",
    "        label = label_batch.numpy()[i]\n",
    "        print(f\"Label : {label} ({class_names[label]})\")\n",
    "        \n",
    "        # Print a separator line for better readability\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX8FtlpGJRE6"
   },
   "source": [
    "## Loading models from TensorFlow Hub\n",
    "\n",
    "For the purpose of this lab, we will be loading a model called Small BERT. Small BERT has the same general architecture as the original BERT but the has fewer and/or smaller Transformer blocks. \n",
    "\n",
    "Some other popular BERT models are BERT Base, ALBERT, BERT Experts, Electra. See the continued learning section at the end of this lab for more info. \n",
    "\n",
    "Aside from the models available below, there are [multiple versions](https://tfhub.dev/google/collections/transformer_encoders_text/1) of the models that are larger and can yeld even better accuracy but they are too big to be fine-tuned on a single GPU. You will be able to do that on the [Solve GLUE tasks using BERT on a TPU colab](https://www.tensorflow.org/tutorials/text/solve_glue_tasks_using_bert_on_tpu).\n",
    "\n",
    "You'll see in the code below that switching the tfhub.dev URL is enough to try any of these models, because all the differences between them are encapsulated in the SavedModels from TF Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a BERT model to fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "y8_ctG55-uTX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n",
      "Models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow Hub URLs for the BERT encoder and preprocessing models\n",
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
    "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "\n",
    "# Print the selected BERT model and preprocessing model URLs\n",
    "print(f\"BERT model selected           : {tfhub_handle_encoder}\")\n",
    "print(f\"Preprocess model auto-selected: {tfhub_handle_preprocess}\")\n",
    "\n",
    "# Verify that the models can be loaded from TensorFlow Hub\n",
    "try:\n",
    "    bert_model = hub.load(tfhub_handle_encoder)  # Load the BERT model\n",
    "    preprocess_model = hub.load(tfhub_handle_preprocess)  # Load the preprocessing model\n",
    "    print(\"Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    # Handle errors during model loading, such as network issues\n",
    "    print(f\"An error occurred while loading the models: {e}\")\n",
    "    print(\"Please check your internet connection and TensorFlow Hub installation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WrcxxTRDdHi"
   },
   "source": [
    "## Preprocessing model\n",
    "\n",
    "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT. TensorFlow Hub provides a matching preprocessing model for each of the BERT models discussed above, which implements this transformation using TF ops from the TF.text library. It is not necessary to run pure Python code outside your TensorFlow model to preprocess text.\n",
    "\n",
    "The preprocessing model must be the one referenced by the documentation of the BERT model, which you can read at the URL printed above. For BERT models from the drop-down above, the preprocessing model is selected automatically.\n",
    "\n",
    "Note: You will load the preprocessing model into a [hub.KerasLayer](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) to compose your fine-tuned model. This is the preferred API to load a TF2-style SavedModel from TF Hub into a Keras model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `hub.KerasLayer` to initialize the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT preprocessing layer created successfully!\n",
      "Sample preprocessing output:\n",
      "input_type_ids: shape = (1, 128)\n",
      "input_mask: shape = (1, 128)\n",
      "input_word_ids: shape = (1, 128)\n"
     ]
    }
   ],
   "source": [
    "# Define the URL for the BERT preprocessing model from TensorFlow Hub\n",
    "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "\n",
    "try:\n",
    "    # Attempt to create the KerasLayer for the BERT preprocessing model\n",
    "    bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    \n",
    "    print(\"BERT preprocessing layer created successfully!\")\n",
    "    \n",
    "    # Optional: Test the preprocessing layer with a sample input\n",
    "    text_test = ['This is a test sentence.']\n",
    "    text_preprocessed = bert_preprocess_model(text_test)\n",
    "    \n",
    "    print(\"Sample preprocessing output:\")\n",
    "    # Print the shapes of the preprocessed output tensors\n",
    "    for key, value in text_preprocessed.items():\n",
    "        print(f\"{key}: shape = {value.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle errors during the creation of the preprocessing layer\n",
    "    print(f\"An error occurred while creating the preprocessing layer: {e}\")\n",
    "    print(\"Please check your internet connection and TensorFlow Hub installation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4naBiEE_cZX"
   },
   "source": [
    "Let's try the preprocessing model on some text and see the output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the preprocess model function and pass text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "r9-zCzJpnuwS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_type_ids', 'input_mask', 'input_word_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Sample input text for testing the BERT preprocessing model\n",
    "text_test = [\"this is such an amazing movie!\"]\n",
    "\n",
    "# Apply the BERT preprocessing model to the sample text\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "# Print the keys of the dictionary returned by the preprocessing model\n",
    "print(f\"Keys       : {list(text_preprocessed.keys())}\")\n",
    "\n",
    "# 1. input_word_ids are the token IDs corresponding to the words in the tokenized sentence\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "\n",
    "# 2. input_mask indicates which tokens should be masked (used in masked language models)\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "\n",
    "# 3. input_type_ids represent the sentence ID for the input sentence\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqL7ihkN_862"
   },
   "source": [
    "As you can see, now you have the 3 outputs from the preprocessing that a BERT model would use (`input_words_id`, `input_mask` and `input_type_ids`).\n",
    "\n",
    "Some other important points:\n",
    "- The input is truncated to 128 tokens. \n",
    "- The `input_type_ids` only have one value (0) because this is a single sentence input. For a multiple sentence input, it would have one number for each input.\n",
    "\n",
    "The text pre-processor is a TensorFlow model. This means that instead of pre-processing separately, we can include it as a layer in the model code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKnLPSEmtp9i"
   },
   "source": [
    "### Using the BERT model\n",
    "\n",
    "Before putting BERT into your own model, let's take a look at its outputs. You will load it from TF Hub and see the returned values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tXxYpK8ixL34",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT encoder layer created successfully!\n"
     ]
    }
   ],
   "source": [
    "# URL for the BERT encoder model from TensorFlow Hub\n",
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
    "\n",
    "try:\n",
    "    # Create the KerasLayer for the BERT encoder model\n",
    "    bert_model = hub.KerasLayer(\n",
    "        tfhub_handle_encoder, \n",
    "        trainable=True,  # Allow the model to be fine-tuned during training\n",
    "        name='BERT_encoder'\n",
    "    )\n",
    "    \n",
    "    print(\"BERT encoder layer created successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any errors that occur during the creation of the BERT encoder layer\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please check your internet connection and TensorFlow Hub installation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_OoF9mebuSZc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape: (1, 512)\n",
      "Pooled Outputs Values: [ 0.7632119   0.9928078  -0.185979    0.36707926  0.15187056  0.65516853\n",
      "  0.96805054 -0.9486895   0.00200426 -0.9877538   0.06841385 -0.9763005 ]\n",
      "Sequence Outputs Shape: (1, 128, 512)\n",
      "Sequence Outputs Values: [[-0.28965798  0.34297633  0.33192655 ...  0.21285358  0.7097396\n",
      "  -0.05782207]\n",
      " [-0.2874166   0.32027632 -0.23044229 ...  0.5847453  -0.21406388\n",
      "   0.72644556]\n",
      " [-0.6605361   0.68883955 -0.87422854 ...  0.10874444 -0.2629265\n",
      "   0.47718439]\n",
      " ...\n",
      " [-0.22528407 -0.28874654 -0.07071439 ...  0.47594494  0.8329531\n",
      "   0.3999489 ]\n",
      " [-0.29790333 -0.27413625 -0.05455249 ...  0.48899072  1.0958607\n",
      "   0.18127438]\n",
      " [-0.44316655  0.00996757  0.07229053 ...  0.17259613  1.1836891\n",
      "   0.07844079]]\n"
     ]
    }
   ],
   "source": [
    "# Pass the preprocessed text through the BERT model\n",
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "# Print the BERT model information and results\n",
    "print(f\"Loaded BERT: {tfhub_handle_encoder}\")\n",
    "\n",
    "# Pooled output is typically used for classification tasks\n",
    "print(f'Pooled Outputs Shape: {bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values: {bert_results[\"pooled_output\"][0, :12]}')\n",
    "\n",
    "# Sequence output is used when you need the full sequence of embeddings\n",
    "print(f'Sequence Outputs Shape: {bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values: {bert_results[\"sequence_output\"][0, :12]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sm61jDrezAll"
   },
   "source": [
    "The BERT models return a map with 3 important keys: `pooled_output`, `sequence_output`, `encoder_outputs`:\n",
    "\n",
    "- `pooled_output` to represent each input sequence as a whole. The shape is `[batch_size, H]`. You can think of this as an embedding for the entire movie review.\n",
    "- `sequence_output` represents each input token in the context. The shape is `[batch_size, seq_length, H]`. You can think of this as a contextual embedding for every token in the movie review.\n",
    "- `encoder_outputs` are the intermediate activations of the `L` Transformer blocks. `outputs[\"encoder_outputs\"][i]` is a Tensor of shape `[batch_size, seq_length, 1024]` with the outputs of the i-th Transformer block, for `0 <= i < L`. The last value of the list is equal to `sequence_output`.\n",
    "\n",
    "For the fine-tuning you are going to use the `pooled_output` array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDNKfAXbDnJH"
   },
   "source": [
    "### Define your model\n",
    "\n",
    "You will create a very simple fine-tuned model, with the preprocessing model, the selected BERT model, one Dense and a Dropout layer.\n",
    "\n",
    "Note: for more information about the base model's input and output you can use copy the model's url to get to the documentation page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the layers in the model will be:\n",
    "1. Input Layer\n",
    "2. Pre-processing Layer\n",
    "3. Encoder Layer\n",
    "4. From the BERT output map, use pooled_output\n",
    "5. Dropout layer\n",
    "6. Dense layer with sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aksj743St9ga",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.393805]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def build_classifier_model(dropout_rate=0.1):\n",
    "    \"\"\"\n",
    "    Builds a binary text classification model using BERT.\n",
    "    \n",
    "    Args:\n",
    "        dropout_rate (float): The dropout rate to be applied after the BERT encoder.\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: A Keras model instance.\n",
    "    \"\"\"\n",
    "    # Input layer expecting raw text input\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"text\")\n",
    "    \n",
    "    # Preprocessing layer from TensorFlow Hub\n",
    "    preprocessing_layer = hub.KerasLayer(\n",
    "        tfhub_handle_preprocess, name=\"preprocessing\"\n",
    "    )\n",
    "    \n",
    "    # Preprocess the input text\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    \n",
    "    # BERT encoder layer from TensorFlow Hub\n",
    "    encoder = hub.KerasLayer(\n",
    "        tfhub_handle_encoder, trainable=True, name=\"BERT_encoder\"\n",
    "    )\n",
    "    \n",
    "    # Get the pooled output from the BERT encoder\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs[\"pooled_output\"]\n",
    "    \n",
    "    # Apply dropout to prevent overfitting\n",
    "    net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
    "    \n",
    "    # Final dense layer with sigmoid activation for binary classification\n",
    "    net = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"classifier\")(net)\n",
    "    \n",
    "    # Create the Keras model\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "\n",
    "# Build the classifier model with a specified dropout rate\n",
    "dropout_rate = 0.15\n",
    "classifier_model = build_classifier_model(dropout_rate)\n",
    "\n",
    "# Test the model with a sample input\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(bert_raw_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTUzNV2JE2G3"
   },
   "source": [
    "The output is meaningless, of course, because the model has not been trained yet.\n",
    "\n",
    "Let's take a look at the model's structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0EmzyHZXKIpm",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'encoder_outputs':  28763649    ['preprocessing[0][0]',          \n",
      "                                 [(None, 128, 512),               'preprocessing[0][1]',          \n",
      "                                 (None, 128, 512),                'preprocessing[0][2]']          \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)],                                               \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 512),                                                       \n",
      "                                 'default': (None,                                                \n",
      "                                512),                                                             \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 512)}                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['BERT_encoder[0][5]']           \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 1)            513         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,764,162\n",
      "Trainable params: 28,764,161\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print the summary of the classifier model to understand its architecture\n",
    "print(classifier_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary: \"model\"\n",
    "\n",
    "This model consists of several layers, with each layer connected to specific outputs from the previous layer. Below is an explanation of each layer and its corresponding attributes:\n",
    "\n",
    "| **Layer (type)**              | **Output Shape**                | **Param #**  | **Connected to**                          |\n",
    "|-------------------------------|---------------------------------|--------------|-------------------------------------------|\n",
    "| **text (InputLayer)**          | `[(None,)]`                     | 0            | This is the input layer that receives raw text input. |\n",
    "| **preprocessing (KerasLayer)** | `{'input_mask': (None, 128),`   | 0            | This layer processes the input text into token IDs, input masks, and type IDs, with each having a shape of `(None, 128)`. Connected to `text[0][0]`. |\n",
    "|                               | `'input_type_ids': (None, 128),` |              | |\n",
    "|                               | `'input_word_ids': (None, 128)}` |              | |\n",
    "| **BERT_encoder (KerasLayer)**  | `{'default': (None, 512),`      | 28,763,649   | This is the BERT encoder layer that generates multiple outputs, including `pooled_output` (shape `(None, 512)`) and `sequence_output` (shape `(None, 128, 512)`). Connected to the outputs from the preprocessing layer. |\n",
    "|                               | `'encoder_outputs': [(None, 128, 512), (None, 128, 512), (None, 128, 512), (None, 128, 512)],` |              | |\n",
    "|                               | `'pooled_output': (None, 512),` |              | |\n",
    "|                               | `'sequence_output': (None, 128, 512)}` |        | |\n",
    "\n",
    "### Parameter Count:\n",
    "- **Trainable params:** `28,764,161` - These parameters are trainable during model training.\n",
    "- **Non-trainable params:** `1` - This is likely a placeholder and indicates no significant non-trainable parameters in this case.\n",
    "\n",
    "The model includes a total of 28,764,161 parameters, almost all of which are trainable, indicating that the BERT model within is being fine-tuned as part of the overall model training process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbUWoZMwc302"
   },
   "source": [
    "## Model training\n",
    "\n",
    "You now have all the pieces to train a model, including the preprocessing module, BERT encoder, data, and classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpJ3xcwDT56v"
   },
   "source": [
    "### Loss function\n",
    "\n",
    "Since this is a binary classification problem and the model outputs a probability (a single-unit layer), you'll use `losses.BinaryCrossentropy` loss function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your loss and evaluation metrics here. Since it is a binary classification use BinaryCrossentropy and BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OWPOZE-L3AgE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the loss function for binary classification\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Define the metric to evaluate the model's performance\n",
    "metrics = tf.metrics.BinaryAccuracy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77psrpfzbxtp"
   },
   "source": [
    "### Optimizer\n",
    "\n",
    "For fine-tuning, let's use the same optimizer that BERT was originally trained with: the \"Adaptive Moments\" (Adam). This optimizer minimizes the prediction loss and does regularization by weight decay (not using moments), which is also known as [AdamW](https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/AdamW).\n",
    "\n",
    "In past labs, we have been using the Adam optimizer which is a popular choice. However, for this lab we will be using a new optimizier which is meant to improve generalization. The intuition and algoritm behind AdamW can be found in this paper [here](https://arxiv.org/abs/1711.05101).\n",
    "\n",
    "For the learning rate (`init_lr`), we use the same schedule as BERT pre-training: linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps (`num_warmup_steps`). In line with the BERT paper, the initial learning rate is smaller for fine-tuning (best of 5e-5, 3e-5, 2e-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "P9eP2y9dbw32",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WarmUp(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    Custom learning rate schedule with a warm-up phase followed by a decay phase.\n",
    "\n",
    "    Args:\n",
    "        initial_learning_rate (float): The initial learning rate before warm-up.\n",
    "        decay_schedule_fn (function): The function that defines the decay schedule after warm-up.\n",
    "        warmup_steps (int): The number of steps for the warm-up phase.\n",
    "    \"\"\"\n",
    "    def __init__(self, initial_learning_rate, decay_schedule_fn, warmup_steps, **kwargs):\n",
    "        super().__init__()\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.warmup_rate = initial_learning_rate / warmup_steps\n",
    "        self.decay_schedule_fn = decay_schedule_fn\n",
    "\n",
    "    def __call__(self, step):\n",
    "        # Adjust learning rate based on whether we're in the warm-up phase or decay phase\n",
    "        lr = tf.cond(\n",
    "            step < self.warmup_steps,\n",
    "            lambda: self.warmup_rate * tf.cast(step, tf.float32),\n",
    "            lambda: self.decay_schedule_fn(step - self.warmup_steps)\n",
    "        )\n",
    "        return lr\n",
    "\n",
    "    def get_config(self):\n",
    "        # Return the configuration of the custom learning rate schedule\n",
    "        return {\n",
    "            \"initial_learning_rate\": self.initial_learning_rate,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"decay_schedule_fn\": self.decay_schedule_fn,\n",
    "        }\n",
    "\n",
    "# Setting up your model and optimizer\n",
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1 * num_train_steps)  # Warm-up for 10% of total steps\n",
    "\n",
    "init_lr = 3e-5  # Initial learning rate\n",
    "\n",
    "# Create the polynomial decay schedule for learning rate\n",
    "decay_schedule_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=init_lr,\n",
    "    decay_steps=num_train_steps,\n",
    "    end_learning_rate=0.0\n",
    ")\n",
    "\n",
    "# Apply custom warm-up schedule with the decay schedule\n",
    "learning_rate_fn = WarmUp(\n",
    "    initial_learning_rate=init_lr,\n",
    "    decay_schedule_fn=decay_schedule_fn,\n",
    "    warmup_steps=num_warmup_steps\n",
    ")\n",
    "\n",
    "# Create the AdamW optimizer with the custom learning rate schedule\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate_fn, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqlarlpC_v0g"
   },
   "source": [
    "### Loading the BERT model and training\n",
    "\n",
    "Using the `classifier_model` you created earlier, you can compile the model with the loss, metric and optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complile the model using the optimizer, loss and metrics you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-7GPDhR98jsD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the classifier model with the specified optimizer, loss function, and metrics\n",
    "classifier_model.compile(optimizer=optimizer, loss=loss, metrics=[metrics])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpBuV5j2cS_b"
   },
   "source": [
    "Note: training time will vary depending on the complexity of the BERT model you have selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HtfDFAnN_Neu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 98s 152ms/step - loss: 0.4926 - binary_accuracy: 0.7469 - val_loss: 0.3678 - val_binary_accuracy: 0.8332\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 91s 145ms/step - loss: 0.3391 - binary_accuracy: 0.8498 - val_loss: 0.3801 - val_binary_accuracy: 0.8368\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 90s 144ms/step - loss: 0.2713 - binary_accuracy: 0.8891 - val_loss: 0.3713 - val_binary_accuracy: 0.8500\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 93s 149ms/step - loss: 0.2259 - binary_accuracy: 0.9117 - val_loss: 0.3909 - val_binary_accuracy: 0.8456\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 93s 148ms/step - loss: 0.2143 - binary_accuracy: 0.9148 - val_loss: 0.3657 - val_binary_accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# Print the BERT model URL being used for training\n",
    "print(f\"Training model with {tfhub_handle_encoder}\")\n",
    "\n",
    "# Train the classifier model\n",
    "history = classifier_model.fit(\n",
    "    x=train_ds,  # Training dataset\n",
    "    validation_data=val_ds,  # Validation dataset\n",
    "    epochs=epochs  # Number of epochs to train\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High-Level Explanation of Training Output\n",
    "\n",
    "**Training model with `https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1`**\n",
    "- Indicates the specific BERT model from TensorFlow Hub being used for training.\n",
    "\n",
    "**Epoch 1/5**\n",
    "- **Epoch 1/5**: Shows that this is the first of 5 training iterations (epochs).\n",
    "\n",
    "**625/625** \n",
    "- The total number of batches processed during each epoch.\n",
    "\n",
    "**[==============================]**\n",
    "- A visual progress bar showing the completion status of the current epoch.\n",
    "\n",
    "**95s** \n",
    "- The total time taken to complete this epoch.\n",
    "\n",
    "**146ms/step** \n",
    "- The average time taken to process each batch (step).\n",
    "\n",
    "**loss: 0.4890**\n",
    "- The loss value after this epoch, representing how well the model is fitting the training data (lower is better).\n",
    "\n",
    "**binary_accuracy: 0.7515**\n",
    "- The accuracy of the model on the training data after this epoch, expressed as a percentage (0.7515 = 75.15%).\n",
    "\n",
    "**val_loss: 0.3822**\n",
    "- The loss value on the validation dataset, indicating how well the model is generalizing to unseen data.\n",
    "\n",
    "**val_binary_accuracy: 0.8286**\n",
    "- The accuracy of the model on the validation dataset, showing how well the model is performing on unseen data, expressed as a percentage (0.8286 = 82.86%).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBthMlTSV8kn"
   },
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Let's see how the model performs. Two values will be returned. Loss (a number which represents the error, lower values are better), and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "slqB-urBV9sP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 79s 100ms/step - loss: 0.3751 - binary_accuracy: 0.8447\n",
      "Loss: 0.37506645917892456\n",
      "Accuracy: 0.8446800112724304\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier model on the test dataset\n",
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uttWpgmSfzq9"
   },
   "source": [
    "### Plot the accuracy and loss over time\n",
    "\n",
    "Based on the `History` object returned by `model.fit()`. You can plot the training and validation loss for comparison, as well as the training and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fiythcODf0xo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting training history data\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "# Assigning the training and validation accuracy and loss values to variables\n",
    "acc = history_dict[\"binary_accuracy\"]\n",
    "val_acc = history_dict[\"val_binary_accuracy\"]\n",
    "loss = history_dict[\"loss\"]\n",
    "val_loss = history_dict[\"val_loss\"]\n",
    "\n",
    "# Defining the range of epochs\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Setting up the figure for plotting\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "# Plotting training and validation loss\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs, loss, \"r\", label=\"Training loss\")  # Red line for training loss\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")  # Blue line for validation loss\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, \"r\", label=\"Training accuracy\")  # Red line for training accuracy\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")  # Blue line for validation accuracy\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzJZCo-cf-Jf"
   },
   "source": [
    "### Explanation of the Training and Validation Plots\n",
    "\n",
    "The images represent two important aspects of model training: **loss** and **accuracy** over the course of training epochs.\n",
    "\n",
    "#### Top Plot: Training and Validation Loss\n",
    "- **X-axis (Epochs)**: Represents the number of training iterations over the entire dataset. The model is trained for 5 epochs in this case.\n",
    "- **Y-axis (Loss)**: Represents the loss value, which is a measure of how well the model's predictions match the true labels. Lower loss values indicate better performance.\n",
    "\n",
    "**Red Line (Training Loss)**:\n",
    "- The red line shows the loss on the training data. \n",
    "- It decreases consistently across epochs, indicating that the model is learning and improving its predictions on the training data.\n",
    "\n",
    "**Blue Line (Validation Loss)**:\n",
    "- The blue line shows the loss on the validation data, which is used to evaluate the model's performance on unseen data.\n",
    "- The validation loss remains relatively stable, slightly decreasing and then plateauing. This suggests that while the model is improving on the training data, its performance on unseen data does not improve significantly after a certain point.\n",
    "\n",
    "#### Bottom Plot: Training and Validation Accuracy\n",
    "- **X-axis (Epochs)**: Represents the number of training epochs.\n",
    "- **Y-axis (Accuracy)**: Represents the accuracy of the model, which is the percentage of correct predictions.\n",
    "\n",
    "**Red Line (Training Accuracy)**:\n",
    "- The red line shows the accuracy on the training data.\n",
    "- It steadily increases across epochs, indicating that the model is getting better at making correct predictions on the training data.\n",
    "\n",
    "**Blue Line (Validation Accuracy)**:\n",
    "- The blue line shows the accuracy on the validation data.\n",
    "- The validation accuracy improves slightly and then remains almost constant, suggesting that the model's ability to generalize to unseen data stabilizes early on and does not improve much after that.\n",
    "\n",
    "### Interpretation\n",
    "- **Training Performance**: The model is learning well on the training data, as indicated by the decreasing training loss and increasing training accuracy.\n",
    "- **Validation Performance**: The relatively flat validation loss and accuracy suggest that the model may have reached its optimal performance on the validation data early in the training process. This can be a sign of a well-trained model, but if the gap between training and validation metrics widens further, it could indicate overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rtn7jewb6dg4"
   },
   "source": [
    "### Export for inference\n",
    "\n",
    "Now you just save your fine-tuned model for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model to saved_model_path for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ShcvqJAgVera"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "# Set the dataset name\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "# Define the path to save the model, formatted with the dataset name\n",
    "saved_model_path = \"./{}_bert\".format(dataset_name.replace(\"/\", \"_\"))\n",
    "\n",
    "# Get the current timestamp in the format YYYYMMDDHHMMSS\n",
    "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# Combine the model path with the timestamp to create a unique export path\n",
    "EXPORT_PATH = os.path.join(saved_model_path, TIMESTAMP)\n",
    "\n",
    "# Save the classifier model to the export path, excluding the optimizer to reduce the saved model size\n",
    "classifier_model.save(EXPORT_PATH, include_optimizer=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbI25bS1vD7s"
   },
   "source": [
    "Let's reload the model so you can try it side by side with the model that is still in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "gUEWVskZjEF0"
   },
   "outputs": [],
   "source": [
    "# Reload the saved model from the specified export path\n",
    "reloaded_model = tf.saved_model.load(EXPORT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyTappHTvNCz"
   },
   "source": [
    "Here you can test your model on any sentence you want, just add to the examples variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "VBWzH6exlCPS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from the saved model:\n",
      "input: this is such an amazing movie! : score: 0.997155\n",
      "input: The movie was great!           : score: 0.983708\n",
      "input: The movie was meh.             : score: 0.958868\n",
      "input: The movie was okish.           : score: 0.055479\n",
      "input: The movie was terrible...      : score: 0.005328\n",
      "\n",
      "Results from the model in memory:\n",
      "input: this is such an amazing movie! : score: 0.997155\n",
      "input: The movie was great!           : score: 0.983708\n",
      "input: The movie was meh.             : score: 0.958868\n",
      "input: The movie was okish.           : score: 0.055479\n",
      "input: The movie was terrible...      : score: 0.005328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "    \"\"\"\n",
    "    Prints the inputs and their corresponding results in a formatted manner.\n",
    "\n",
    "    Args:\n",
    "        inputs (list): List of input strings.\n",
    "        results (list): List of results corresponding to each input.\n",
    "    \"\"\"\n",
    "    result_for_printing = [\n",
    "        f\"input: {inputs[i]:<30} : score: {results[i][0]:.6f}\"\n",
    "        for i in range(len(inputs))\n",
    "    ]\n",
    "    print(*result_for_printing, sep=\"\\n\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Example sentences to test the model\n",
    "examples = [\n",
    "    \"this is such an amazing movie!\",  # Same sentence as used earlier\n",
    "    \"The movie was great!\",\n",
    "    \"The movie was meh.\",\n",
    "    \"The movie was okish.\",\n",
    "    \"The movie was terrible...\",\n",
    "]\n",
    "\n",
    "# Get predictions from the reloaded model\n",
    "reloaded_results = reloaded_model(tf.constant(examples))\n",
    "\n",
    "# Get predictions from the original model in memory\n",
    "original_results = classifier_model(tf.constant(examples))\n",
    "\n",
    "# Print results from the saved model\n",
    "print(\"Results from the saved model:\")\n",
    "print_my_examples(examples, reloaded_results)\n",
    "\n",
    "# Print results from the model currently in memory\n",
    "print(\"Results from the model in memory:\")\n",
    "print_my_examples(examples, original_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continued Learning\n",
    "\n",
    "In this lab, we chose small BERT to train our text classifier. There are other pre-trained BERT models which you can find here. Consider experiementing with some of these. However, remember that the bigger the model you choose to fine-tune, the longer it will take to train.\n",
    "\n",
    "There are \n",
    "  - [BERT-Base](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3), [Uncased](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3) and [seven more models](https://tfhub.dev/google/collections/bert/1) with trained weights released by the original BERT authors.\n",
    "  - [Small BERTs](https://tfhub.dev/google/collections/bert/1) have the same general architecture but fewer and/or smaller Transformer blocks, which lets you explore tradeoffs between speed, size and quality.\n",
    "  - [ALBERT](https://tfhub.dev/google/collections/albert/1): four different sizes of \"A Lite BERT\" that reduces model size (but not computation time) by sharing parameters between layers.\n",
    "  - [BERT Experts](https://tfhub.dev/google/collections/experts/bert/1): eight models that all have the BERT-base architecture but offer a choice between different pre-training domains, to align more closely with the target task.\n",
    "  - [Electra](https://tfhub.dev/google/collections/electra/1) has the same architecture as BERT (in three different sizes), but gets pre-trained as a discriminator in a set-up that resembles a Generative Adversarial Network (GAN).\n",
    "  - BERT with Talking-Heads Attention and Gated GELU [[base](https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1), [large](https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_large/1)] has two improvements to the core of the Transformer architecture.\n",
    "\n",
    "The model documentation on TensorFlow Hub has more details and references to the\n",
    "research literature.\n",
    "\n",
    "Aside from the models available above, there are [multiple versions](https://tfhub.dev/google/collections/transformer_encoders_text/1) of the models that are larger and can yeld even better accuracy but they are too big to be fine-tuned on a single GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### License\n",
    "\n",
    "Copyright 2022 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classify_text_with_bert.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "glabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
